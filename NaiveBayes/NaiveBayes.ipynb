{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NavieBayes\n",
    "\n",
    "## 贝叶斯定理\n",
    "\n",
    "$$\n",
    "    P(A|B) = \\frac{P(A)P(B|A)}{P(B)}\n",
    "$$\n",
    "\n",
    "即求解在B的条件下，A发生的概率，可以用P(A)先验概率和P(B|A)条件概率求得，分母为归一化因子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯\n",
    "\n",
    "通过上述公式，我们可以用贝叶斯来求解分类问题。\n",
    "\n",
    "其中$B = \\{{ x_1,x_2,\\cdots,x_n}\\}$ 表示样本特征，即要分类的样本所具有的属性，如西瓜书中，｛青绿，蜷缩，浊响...｝分别对应$x_1,x_2,\\cdots,x_n$,\n",
    "\n",
    "$A = \\{{y_1,y_2,\\cdots,y_n}\\}$表示样本类别，即样本属于要分类的哪一类，如西瓜书中的｛好瓜，坏瓜｝。\n",
    "\n",
    "这样，一个分类问题用贝叶斯公式表示为：\n",
    "$$\n",
    "    P(y_i|\\boldsymbol{x}) = \\frac{P(y_i)P(\\boldsymbol{x}|y_i)}{P(\\boldsymbol{x})}\n",
    "$$\n",
    "\n",
    "其中，$P(y_i|\\boldsymbol{x})$表示zai在获取到观测值$\\boldsymbol{x}$时，它属于类别$y_i$的概率，$\\boldsymbol{x}=\\{{ x_1,x_2,\\cdots,x_n}\\}$\n",
    "\n",
    "因此，我们可以计算出对应于每一个i时，其所属类别的概率，选择最大的那个即为分类类别。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何求解呢？\n",
    "\n",
    "首先$P(y_i) =\\frac{N_{y_i}}{N}$，$N_{y_i}$为$y_i$类别出现的频数，N为样本总数，即我们用频率近似代替了概率。\n",
    "\n",
    "分母部分$P({\\boldsymbol{x}})$对于所有类别都一样，我们要的结果只是每个概率的相对大小，故该项可以省略。\n",
    "\n",
    "对于$P(\\boldsymbol{x}|y_i)$,在此处就体现了朴素贝叶斯的“朴素”之处，假设各个特征之间相互独立，因此可以展开为$P(x_1|y_i)P(x_2|y_i)\\cdots P(x_n|y_i)$\n",
    "\n",
    "即计算在$y_i$条件下每个特征出现的概率。详细可以参考[维基百科](https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8)\n",
    "\n",
    "这样就可以计算每一个$P(y_i|\\boldsymbol{x})$了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高斯朴素贝叶斯\n",
    "\n",
    "当特征为连续值时，如何计算$P(\\boldsymbol{x}|y_i)$呢？\n",
    "\n",
    "GaussianNB解决了该问题，它假设每一个特征服从高斯分布，即在属于$y_i$类别的样本中，每一维特征都符合高斯分布，因此可以计算得出$\\mu$和\n",
    "\n",
    "$\\sigma$,对于要预测的样本，通过$\\mu$和$\\sigma$计算出概率密度，朴素贝叶斯的训练过程其实就是对这两个参数的估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多项式朴素贝叶斯\n",
    "\n",
    "当特征为离散值时，通过多项式朴素贝叶斯求解$P(\\boldsymbol{x}|y_i)$\n",
    "\n",
    "即$P(y_i) = \\frac{N_{y_i}}{N}$,$N_{y_i}$为类别$y_i$出现的次数，N为总的样本数\n",
    "\n",
    "$P(x_j|y_i) = \\frac{N_{y_i,x_j}}{N_{y_i}}$，$N_{y_i,x_j}$为在$y_i$类别下$x_j$出现的次数，j从１到样本特征总数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑一种情况，当某个属性值在训练集中从来没与某个类别同时出现过，则$P(x_j|y_i) = 0$，则在计算$P(x_1|y_i)P(x_2|y_i)\\cdots P(x_n|y_i)$时，不论其他项\n",
    "\n",
    "为多少，结果都为0，这是我们不想看到的。即因为这一项，而忽略了其他因素对于结果的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决该问题的常用方法为进行平滑，令K表示训练集N中可能的类别数，$K_j$表示第j个属性可能取值数。则计算公式可修改为\n",
    "\n",
    "$P(y_i) = \\frac{N_{y_i}+\\alpha}{N+\\alpha K}$\n",
    "\n",
    "$P(x_j|y_i) = \\frac{N_{y_i,x_j}+\\alpha}{N_{y_i}+\\alpha K_i}$\n",
    "\n",
    "$\\alpha$为平滑值，$\\alpha = 1$时，为Laplace平滑，$0 <\\alpha<1 $时，为Lidstone平滑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 伯努利朴素贝叶斯\n",
    "\n",
    "与多项式模型类似，伯努利模型适用于离散值的情况，只不过每个特征的取值只能为０和１，计算方式与多项式模型类似。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
