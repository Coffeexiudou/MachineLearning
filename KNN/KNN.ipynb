{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN k-nearest neighbor K近邻算法\n",
    "\n",
    "是一种基本的分类与回归算法。\n",
    "\n",
    "K近邻算法不具备显示的学习过程。\n",
    "\n",
    "K近邻算法的三要素：**K值选择、距离度量、分类决策规则**\n",
    "\n",
    "## K近邻算法步骤：\n",
    "１．输入训练数据集T及要预测的特征向量x；\n",
    "\n",
    "２．根据给定的距离度量方式，在训练集T中找到与x最近邻的k个点，涵盖这k个点的x的邻域记作N；\n",
    "\n",
    "３．在N中根据分类决策决定x的类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K值的选择\n",
    "\n",
    "k值的选择会对k近邻法的结果产生重大影响。\n",
    "\n",
    "1.若k值选择过小，相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差(approximation error)会减小，只有与输入实例较近的训练实例才会对预测起作用，但缺点是“学习”\n",
    "的估计误差(estimation error)会增大，预测结果会对近邻的实例点非常敏感，如恰巧是噪声，预测就会出错；即k值减小，意味着整体模型变得复杂，容易发生过拟合。\n",
    "\n",
    "2.若k值选择过大，相当于用较大的邻域中的训练实例进行预测，优点是可以减少学习的估计误差，但缺点是近似误差会增大；k值的增大意味着整体的模型变得简单。\n",
    "\n",
    "实际应用中，k值一般取一个比较小的值，通常**采用交叉验证法**来选取最优的k值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 距离度量\n",
    "\n",
    "特征空间中两个实例点的距离是两个实例点相似程度的反映。k近邻算法一般使用的距离是**欧氏距离**，但也可以选择其他距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类决策规则　\n",
    "\n",
    "k近邻法中的分类决策规则往往是多数投票，对于回归即取均值。但也可以使用加权投票或者加权求均值的方式。\n",
    "\n",
    "多数投票规则等价于经验风险最小化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K近邻法的实现\n",
    "\n",
    "实现k近邻法时，主要考虑的问题就是如何对训练数据进行快速k近邻搜索，在特征空间的维数大及训练数据容量大时尤其必要。\n",
    "\n",
    "#### 线性扫描\n",
    "\n",
    "这是一种最简单的实现方法，即计算输入实例与每一个训练实例的距离，当训练集很大时，计算非常耗时。\n",
    "\n",
    "#### kd树\n",
    "\n",
    "kd树是一种对k维空间中实例点进行存储以便对其进行快速检索的树形数据结构。它是二叉树。\n",
    "\n",
    "构造kd树：\n",
    "\n",
    "１．开始：构造根结点。选择第１维为坐标轴，以数据集中所有实例的第一维坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域，切分由通过切分点并与坐标轴x(1)垂直的超平面实现。由根结点生成深度为１的左右子结点：左子结点对应坐标x(1)小于切分点的子区域，右子结点对应坐标x(1)大于切分点的子区域。将落在切分超平面上的实例点保存在根结点。\n",
    "\n",
    "２．重复：对深度为j的结点，选择x(l)为切分坐标轴，l=j(mod k)+1，以该结点的区域中所有实例的x(l)坐标的中位数为切分点，将该结点对应的超矩形区域切分为两个子区域，切分由通过切分点并与坐标轴x(l)垂直的超平面实现。由该结点生成深度为j+1的左右子结点：左子结点对应坐标x(l)小于切分点的子区域，右子结点对应坐标x(l)大于切分点的子区域。将落在切分超平面上的实例点保存在该结点。\n",
    "\n",
    "３．直到两个子区域没有实例存在时停止。从而形成kd树的区域划分。\n",
    "\n",
    "\n",
    "搜索kd树：\n",
    "１．在kd树中找到包含目标点x的叶节点：从根结点出发，类似于二分查找，按照每层结点的划分维度，与目标结点该维度的值进行比较，目标结点该维度的值小则移动到左子结点，否则移动到右子结点。直到子结点为叶节点为止。将经过的结点依次加入searchpath，这是一个栈，同时计算每一个经过的结点中保存的实例点与目标点间的距离，若比当前最短距离更近，则更新最短距离及最近点（最短距离初始化为无穷大）。\n",
    "\n",
    "２．while循环条件为当searchpath不为空时，从栈中取出一个实例，判断该实例在其划分维度d的坐标值与目标点在维度d的坐标值的差的绝对值和当前最短距离的大小，若小于当前最短距离，则证明可能存在更短的距离，此时，若该结点为叶节点，则直接进入下一轮while循环，继续弹栈；若该结点不为叶节点，则判断目标点d维坐标值是否大于该结点实例点d维坐标值，若大于，则移动到该结点的左子结点，反之移动到右子结点；将移动后的结点加入到searchpath中，计算该结点中的实例点与目标点的距离，若更近，则更新最短距离和最近点；继续while循环。\n",
    "\n",
    "３．返回最近结点（可在上述过程中构建最近点列表，将所有计算过距离的点加入该列表，可用来计算k近邻）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考\n",
    "\n",
    "[http://blog.csdn.net/silangquan/article/details/41483689]\n",
    "\n",
    "[http://blog.csdn.net/u010551621/article/details/44813299]\n",
    "\n",
    "[http://www.cnblogs.com/21207-iHome/p/6084670.html]\n",
    "\n",
    "[http://scipy-cookbook.readthedocs.io/items/KDTree_example.html]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
